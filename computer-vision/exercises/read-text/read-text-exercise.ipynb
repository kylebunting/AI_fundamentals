{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Read Text With Computer Vision Service\n",
    "\n",
    "In this notebook, use the `ComputerVisionClient` object found in the Azure Cognitive Services Python SDK to explore the Optical Character Recognition (OCR) capabilities of Azure Computer Vision.\n",
    "\n",
    "> **Important**: Several cells in this notebook contain `TODO` statements, where you need to update variables or enter code to enable the cell to execute without errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the notebook\n",
    "\n",
    "### Install the Azure Cognitive Service Computer Vision Library\n",
    "\n",
    "To access the Computer Vision service from this Python notebook, you need to install the Azure Cognitive Services Computer Vision Library. This library is part of the [Azure SDK for Python](https://github.com/Azure/azure-sdk-for-python) GitHub project.\n",
    "\n",
    "> To learn more, read the [Azure Cognitive Services modules for Python](https://docs.microsoft.com/python/api/overview/azure/cognitive-services?view=azure-python) article in Microsoft Docs.\n",
    "\n",
    "`TODO`: In the cell below, complete the `pip install` command to install the Azure Cognitive Services Computer Vision library, and then execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install # TODO: Complete this line to install the Azure Cognitive Services Computer Vision library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and services\n",
    "\n",
    "In addition to the Computer Vision library, we will also make use of a few other Python libraries in this notebook. Run the following cell to import the libraries and reference the services required to execute the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries need to access the Computer Vision services\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Import a few utility libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variables\n",
    "\n",
    "To access your Computer Vision service, its authentication key and endpoint URL need to be supplied to client applications.\n",
    "\n",
    "### Retrieve and set the `key` and `endpoint` values from your Custom Vision prediction service.\n",
    "\n",
    "`TODO`: Using the values from the `Keys and Endpoints` page for you Custom Vision prediction service, replace the tokenized values in the cell below, as follows:\n",
    "\n",
    "- Retrieve the `Key 1` value for your prediction cognitive services resource in the Azure portal and update the `key` value below.\n",
    "- Retrieve the `Endpoint` value for your prediction cognitive services resource in the Azure portal and update the `endpoint` value below.\n",
    "\n",
    "> **Important**: You **must** replace the variable values below with the values from your Custom Vision prediction endpoint or the remaining cells in this notebook will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update the values assigned to the variables below\n",
    "key = 'YOUR_COGNITIVE_SERVICES_KEY'\n",
    "endpoint = 'YOUR_COGNITIVE_SERVICES_ENDPOINT'\n",
    "\n",
    "print('Ready to perform OCR using the Computer Vision service at \"{}\" using the key \"{}.\"''\"'.format(endpoint, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Computer Vision client\n",
    "\n",
    "After setting the `key` and `endpoint` needed to access your Computer Vision service, you can instantiate a client.\n",
    "\n",
    "`TODO`: Complete the code below to instantiate a new `ComputerVisionClient`, authenticating against your Azure Cogntive Services account, and then execute the cell below to create the `ComputerVisionClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Computer Vision client\n",
    "credentials = CognitiveServicesCredentials(key)\n",
    "client = # TODO: Complete this line to create a new Computer Vision Client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the OCR API\n",
    "\n",
    "### Read text from an image\n",
    "\n",
    "Use the optical character recognition (OCR) API to extract text from images. The image is of a street sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Create a matplotlib figure to display the classification results\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Read an image file into a stream\n",
    "path = os.path.join('images', 'sign.jpg')\n",
    "\n",
    "# Extract text from the image using the Computer Vision service\n",
    "with open(path, \"rb\") as stream:\n",
    "    ocr = client.recognize_printed_text_in_stream(stream)\n",
    "\n",
    "text = ''\n",
    "\n",
    "# Process the OCR text one line at a time\n",
    "for region in ocr.regions:\n",
    "    for line in region.lines:\n",
    "        # Read the OCR'ed text from each line\n",
    "        for word in line.words:\n",
    "            text += word.text + ' '\n",
    "\n",
    "# Display the image with its extracted text\n",
    "img = Image.open(path)\n",
    "draw = ImageDraw.Draw(img)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "fig.suptitle(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add bounding boxes\n",
    "\n",
    "Using the OCR API, you can also draw bounding boxes around each unique string of text identified during the OCR process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matplotlib figure to display the classification results\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Display the image with its extracted text inside bounding boxes\n",
    "img = Image.open(path)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Process the text one line at a time, drawing the appropriate bounding box\n",
    "for region in ocr.regions:\n",
    "    for line in region.lines:\n",
    "        # Draw the bounding box for each line of text\n",
    "        l,t,w,h = list(map(int, line.bounding_box.split(',')))\n",
    "        draw.rectangle(((l,t), (l+w, t+h)), outline='magenta', width=5)\n",
    "\n",
    "# Show the image with the text locations highlighted by bounding boxes\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "fig.suptitle(text) "
   ]
  },
  {
   "source": [
    "## Using the Read API\n",
    "\n",
    "The `Read API` is the preferred way of performing OCR functions using Computer Vision. While the `OCR API` is still available, it is more limited in its capabilities and is in the process of being deprecated. To help provide a better understanding of the `Read API`, let's look at some of the operations available through the Python SDK `ComputerVisionClient` object.\n",
    "\n",
    "## Read scanned documents\n",
    "\n",
    "The `Read API` is designed to handle reading larger amounts of text from scanned documents, for example.\n",
    "\n",
    "To use the `Read API`, you must send an image to the Computer Vision service and it will be read and analyzed asynchronously by the service. This means you must send follow-on requests to check the status of the operation and retrieve the results when processing is completed.\n",
    "\n",
    "`TODO`: In the cell below, there are two `TODO` statements where you need to complete the code.\n",
    "\n",
    "- For the first `TODO`, complete the line `operation = client.` so that you can asynchronously send the image to be processed by the `Read API`.\n",
    "- The second `TODO` relates to checking the status of your read request. Complete the line `result = client.` to add a check for the result of the read operation.\n",
    "\n",
    "Once the `TODOs` have been completed, execute the cell below to send an image to your Computer Vision service and then wait for the results. When results are available, retrieve and display them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Read a scanned image into a stream\n",
    "path = os.path.join('images', 'diagnosis.jpg')\n",
    "\n",
    "# Send an async request to read text within the image\n",
    "with open(path, \"rb\") as stream:\n",
    "    operation = client.# TODO: Complete this line to end a read request to the Read API\n",
    "    \n",
    "# Extract the operation ID from the response headers\n",
    "locationHeader = operation.headers[\"Operation-Location\"]\n",
    "operationId = locationHeader.split(\"/\")[-1]\n",
    "\n",
    "# Wait for the asynchronous operation to complete\n",
    "while True:\n",
    "    result = client.# TODO: Complete this line to request the read result from the Read API.\n",
    "    if result.status not in [OperationStatusCodes.running]:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# When the operation has completed successfully, print each line of text returned to the output\n",
    "if result.status == OperationStatusCodes.succeeded:\n",
    "    for res in result.analyze_result.read_results:\n",
    "        for line in res.lines:\n",
    "            print(line.text)\n",
    "\n",
    "# Display the image analyzed for comparision to the OCR'ed text results\n",
    "print('\\n')\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "img = Image.open(path)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PDF documents\n",
    "\n",
    "In addition to reading scanned documents, the `Read API` is specifically designed to process vast amounts of text found in documents, such as PDFs. Unlike the `OCR API`, the `Read API` performs OCR operations asynchronously, allowing it to handle large documents and not lock processing threads in applications while waiting for results.\n",
    "\n",
    "`TODO`: In the cell below, there are three `TODO` statements where you need to complete the code.\n",
    "\n",
    "- For the first `TODO`, complete the line `operation = client.` so that you can asynchronously send the image to be processed by the `Read API`.\n",
    "- The second `TODO` relates to checking the status of your read request. Complete the line `result = client.` to add a check for the result of the read operation.\n",
    "- In the final `TODO`, complete the line to retrieve the read results of the OCR operation.\n",
    "\n",
    "Once the `TODOs` have been completed, execute the cell below to send an image to your Computer Vision service and then wait for the results. When results are available, retrieve and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a PDF document into a stream\n",
    "path = os.path.join('docs', 'knowledge-mining.pdf')\n",
    "\n",
    "# Send an async request to read text within the document\n",
    "with open(path, \"rb\") as stream:\n",
    "    operation = client.# TODO: Complete this line to end a read request to the Read API\n",
    "\n",
    "# Extract the operation ID from the response headers\n",
    "locationHeader = operation.headers[\"Operation-Location\"]\n",
    "operationId = locationHeader.split(\"/\")[-1]\n",
    "\n",
    "# Wait for the asynchronous operation to complete\n",
    "while True:\n",
    "    result = client.# TODO: Complete this line to request the read result from the Read API.\n",
    "    if result.status not in [OperationStatusCodes.running]:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# When the operation has completed successfully, print each line of text returned to the output\n",
    "if result.status == OperationStatusCodes.succeeded:\n",
    "    for res in result.analyze_result.# TODO: Complete this line read the results of the OCR operation.\n",
    "        for line in res.lines:\n",
    "            print(line.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Handwritten Text\n",
    "\n",
    "In addition to printed text, the `Read API` is also capable of reading handwritten text.\n",
    "\n",
    "`TODO`: In the cell below, there are three `TODO` statements where you need to complete the code.\n",
    "\n",
    "- For the first `TODO`, complete the line `operation = client.` so that you can asynchronously send the image to be processed by the `Read API`.\n",
    "- The second `TODO` relates to checking the status of your read request. Complete the line `result = client.` to add a check for the result of the read operation.\n",
    "- In the final `TODO`, complete the line to retrieve the read results of the OCR operation.\n",
    "\n",
    "Once the `TODOs` have been completed, execute the cell below to send an image to your Computer Vision service and then wait for the results. When results are available, retrieve and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Read an image file into a stream\n",
    "path = os.path.join('images', 'note.jpg')\n",
    "\n",
    "# Send an async request to read text within the image\n",
    "with open(path, \"rb\") as stream:\n",
    "    operation = client.# TODO: Complete this line to end a read request to the Read API\n",
    "    \n",
    "# Extract the operation ID from the response headers\n",
    "locationHeader = operation.headers[\"Operation-Location\"]\n",
    "operationId = locationHeader.split(\"/\")[-1]\n",
    "\n",
    "# Wait for the asynchronous operation to complete\n",
    "while True:\n",
    "    result = client.# TODO: Complete this line to request the read result from the Read API.\n",
    "    if result.status not in [OperationStatusCodes.running]:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# When the operation has completed successfully, print each line of text returned to the output\n",
    "if result.status == OperationStatusCodes.succeeded:\n",
    "    for res in result.analyze_result.# TODO: Complete this line read the results of the OCR operation.\n",
    "        for line in res.lines:\n",
    "            print(line.text)\n",
    "\n",
    "# Display the image analyzed for comparision to the OCR'ed text results\n",
    "print('\\n')\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "img = Image.open(path)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}